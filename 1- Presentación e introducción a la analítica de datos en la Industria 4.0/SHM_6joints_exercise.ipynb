{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Método de análisis basado en técnicas de clustering para la detección de daño estructural "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El presente trabajo de investigación forma parte del proyecto de monitorización del estado de salud estructural del Sydney Harbour Bridge (Australia).\n",
    "\n",
    "Los objetivos del método planteado son:\n",
    "   1. Identificar clusters de las partes del puente que presentan un comportamiento similar, a partir de los datos monitorizados\n",
    "   2. Complementar las técnicas actuales de detección de daño estructural\n",
    "   3. Conocer el comportamiento global del puente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# librerías genéricas que utilizaremos\n",
    "from pandas import DataFrame, read_csv\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from scipy.fftpack import fft\n",
    "import scipy.signal.signaltools as sigtool\n",
    "import sklearn.preprocessing as pre\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# especificamos variables globales, como por ejemplo el directorio donde tenemos los datos\n",
    "import glob, os\n",
    "path = r'./data/6_nodes/' \n",
    "\n",
    "# cargamos nuestro métodos\n",
    "%run outliers_removal.py\n",
    "%run data_processing.py\n",
    "%run kmeans.py\n",
    "%run map_pairwise_distances.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caso de estudio 1: ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 6 juntas del segmento Norte del puente monitorizadas durante una semana\n",
    "- La junta número 4 presenta daño estructural en forma de grietas\n",
    "- Los eventos son registrados y estandarizados a series temporales de 600 valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se podría mejorar este método?\n",
    "def load_6joints_data(csv_files_path=path):\n",
    "    '''\n",
    "    Method that loads sensor data related to 6 joints test (it must be customised depending on the file format, this is just a template).\n",
    "        Inputs:\n",
    "            - csv_files_path: the path in which the csv data files can be found            \n",
    "        Outputs: (datav1, joints) loaded v1 data (matrix [m,n]) and the list of joints (array [m])\n",
    "    '''       \n",
    "    c = -1            \n",
    "    datav1 = []\n",
    "    joints = []    \n",
    "    all_files = glob.glob(os.path.join(csv_files_path, \"data_6nodes_chunk*.csv\"))    \n",
    "    for csv_file in all_files:\n",
    "        for line in open(csv_file):        \n",
    "            c += 1\n",
    "            if (6329 < c <= 12653):        \n",
    "                joints.append(1)            \n",
    "                csv_row = line.split(',')[1:599]\n",
    "                tmp = [float(i) for i in csv_row]\n",
    "                datav1.append(np.array(tmp))\n",
    "            elif (26215 < c <= 33452):        \n",
    "                joints.append(2)\n",
    "                csv_row = line.split(',')[1:599]\n",
    "                tmp = [float(i) for i in csv_row]\n",
    "                datav1.append(np.array(tmp))\n",
    "            elif (45675 < c <= 50659):        \n",
    "                joints.append(3)\n",
    "                csv_row = line.split(',')[1:599]\n",
    "                tmp = [float(i) for i in csv_row]\n",
    "                datav1.append(np.array(tmp))\n",
    "            elif (62529 < c <= 69415):        \n",
    "                joints.append(4)\n",
    "                csv_row = line.split(',')[1:599]\n",
    "                tmp = [float(i) for i in csv_row]\n",
    "                datav1.append(np.array(tmp))\n",
    "            elif (83019 < c <= 89734):        \n",
    "                joints.append(5)\n",
    "                csv_row = line.split(',')[1:599]\n",
    "                tmp = [float(i) for i in csv_row]\n",
    "                datav1.append(np.array(tmp))\n",
    "            elif (101251 < c <= 106052):        \n",
    "                joints.append(6)      \n",
    "                csv_row = line.split(',')[1:599]\n",
    "                tmp = [float(i) for i in csv_row]\n",
    "                datav1.append(np.array(tmp))\n",
    "            else:\n",
    "                continue            \n",
    "    return pd.concat(datav1), joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos los datos\n",
    "datav1, joints = load_6joints_data(path)\n",
    "# ¿cuántos vectores de características tenemos y de qué tamaño son?\n",
    "print ('Dimensiones de los datos de entrada: ' + str(datav1.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un primer vistazo a los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# graficamos un vector de características\n",
    "plt.figure(figsize=(24, 12))\n",
    "plt.plot(datav1.values[0], lw=3)\n",
    "plt.xlabel('time (s)', fontsize=24)\n",
    "plt.ylabel('magnitude', fontsize=24)\n",
    "plt.tick_params(labelsize=20)\n",
    "plt.ylim(-11,11)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estandarización de los datos\n",
    "from numpy import mean, std\n",
    "datav1 = (datav1.values - mean(datav1.values, axis=0)) / std(datav1.values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostramos un vector de características tras estandarizar los datos originales\n",
    "plt.figure(figsize=(24, 12))\n",
    "plt.plot(datav1[0], lw=3)\n",
    "plt.xlabel('time (s)', fontsize=24)\n",
    "plt.ylabel('magnitude', fontsize=24)\n",
    "plt.tick_params(labelsize=20)\n",
    "plt.ylim(-11,11)\n",
    "plt.grid()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información contextual: posición y distribución de las juntas del puente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joints=np.array(joints)\n",
    "joints=joints.reshape(joints.shape[0])\n",
    "joints_dist = [[1],[2],[3],[4],[5],[6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminar outliers y ruido de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Método que elimina outliers para limpiar y hacer un remuestreo de los datos, de tal modo que para cada junta eliminamos los eventos cuya energía está lejos de la media. \n",
    "    Entradas:\n",
    "        - data: conjunto de datos de entrenamiento, con los eventos que vamos a procesar (matrix [m,n])\n",
    "        - index: la lista de juntas a las que pertenece cada evento (array [m])\n",
    "        - k: número de vecinos a considerar por el KDTree y máximo número de eventos a obtener por junta\n",
    "        - normalityLoops: criterio de parada principal\n",
    "        - anomaly_threshold: desviaciones típicas respecto de la media a utilizar\n",
    "    Salidas: (reduced_data, reduced_index, samples_distribution) objetos que contienen los datos procesados, las etiquetas (juntas) correspondientes y la distribución final de juntas resultantes \n",
    "'''\n",
    "# utilizar un número diferente de vecinos, 'k', iteraciones, 'normalityLoops' y desviaciones típicas, 'anomaly_threshold'\n",
    "reduced_data, reduced_index, samples_distribution, removed_data, removed_index = outliers_removal(datav1, \n",
    "                                                                                                  joints, \n",
    "                                                                                                  k=5000, \n",
    "                                                                                                  normalityLoops=1,\n",
    "                                                                                                  anomaly_threshold=2)\n",
    "# mostramos el número de muestras resultantes\n",
    "print ('Dimensiones de los datos procesados: ' + str(reduced_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformada de Fourier (FFT): del dominio temporal al dominio en frecuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicamos FFT a los datos estandarizados\n",
    "reduced_data_fft = np.fft.rfft(reduced_data)\n",
    "reduced_data_fft = np.abs(reduced_data_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostramos una señal en frecuencias resultante\n",
    "plt.figure(figsize=(24, 12))\n",
    "plt.plot(reduced_data_fft[0], lw=3)\n",
    "plt.xlabel('frequency (Hz)', fontsize=24)\n",
    "plt.ylabel('amplitude', fontsize=24)\n",
    "plt.tick_params(labelsize=20)\n",
    "plt.xlim(0,300)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering basado en eventos: K-medias (distancia Euclídea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probar con los datos originales y con un número diferente de clusters, 'n_clusters'\n",
    "from sklearn.cluster import KMeans\n",
    "'''\n",
    "Método K-medias basado en la implementación de sklearn.\n",
    "    Entradas:\n",
    "        - data: conjunto de datos de entrenamiento, con los eventos que vamos a procesar (matrix [m,n])\n",
    "        - n_clusters: número de clusters a utilizar\n",
    "    Outputs: (Z, centroids, kmeans) array que contiene el cluster al que pertenece cada evento (array [m]), centroides o valores medios (matrix [m, n_clusters]) y el modelo kmeans resultante\n",
    "'''\n",
    "kmeans = KMeans(init='k-means++', n_clusters=2, n_init=20)\n",
    "kmeans.fit(reduced_data_fft)\n",
    "Z = kmeans.labels_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenemos los centroides\n",
    "centroids = kmeans.cluster_centers_\n",
    "inertia = kmeans.inertia_      \n",
    "print('Sumatorio de distancias de los eventos a los centroides de los clusters más cercanos: ' + str(inertia))\n",
    "final_u = Z \n",
    "final_centroids = centroids\n",
    "final_dist = kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Método que muestra los resultados del clustering.\n",
    "    Entradas:\n",
    "        - data: conjunto de datos con los eventos que vamos a procesar (matrix [m,n])\n",
    "        - index: la lista de juntas a las que pertenece cada evento (array [m])\n",
    "        - samples_distribution: distribución de las juntas, una fila por cada set de jutas que pertenecen a una misma zona del puente y que tendrán el mismo color en el grafo\n",
    "        - centroids: centroides o valores medios (matrix [m, n_clusters])\n",
    "        - Z: array que contiene el cluster al que pertenece cada evento (array [m])\n",
    "        - njoints: 6 o 71, en base al caso de estudio planteado\n",
    "    Salidas: cada cluster se representa mediante 2 grafos, el de la parte superior muestra el centroide y la desviación típica de los eventos agrupados en el cluster y en la parte inferior se muestra la distribución de los eventos\n",
    "'''\n",
    "draw_clustering_results(reduced_data_fft,reduced_index,joints_dist,final_centroids,final_u,njoints=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering basado en juntas: mapa de distancias entre los representantes de las juntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probar con los datos originales\n",
    "'''\n",
    "Método que calcula la media de los eventos correspondientes a cada junta (señales representativas de cada junta).\n",
    "    Entradas:\n",
    "        - data: conjunto de datos de entrenamiento, con los eventos que vamos a procesar (matrix [m,n])\n",
    "        - labels: la lista de juntas a las que pertenece cada evento (array [m])\n",
    "        - samples_distribution: distribución de las juntas, una fila por cada set de jutas que pertenecen a una misma zona del puente y que tendrán el mismo color en el grafo\n",
    "    Salidas: (means, joints) las señales representativas de cada junta, o valores medios (matrix [j,n], j=número de juntas diferentes) y joints la lista con las etiquetas de las juntas (array [j])\n",
    "'''    \n",
    "means, joints = calculate_joints_means(reduced_data_fft, reduced_index, joints_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probar usando otras métricas de distancia: ¿con cuál se obtienen los mejores resultados?\n",
    "'''\n",
    "Método que crea un mapa o matriz de distancias.\n",
    "    Entradas:\n",
    "        - centroids: los representates de las juntas (matrix [j,n])            \n",
    "        - labels: las etiquetas de las juntas (array [j])        \n",
    "        - weights: pesos de los centroides (array [m]) \n",
    "        - distance: métrica de distancia a aplicar: Euclidean, Manhattan, Correlation, Minkowski, Minkowski_pthPower, Chebyshev\n",
    "        - p: pthPower utilizado en la distancia de Minkowski\n",
    "    Salidas: (global_matrix) el mapa o matriz de distancias resultante (matrix [m,m])\n",
    "''' \n",
    "draw_matrix_of_distances(means, joints, njoints=6, weights=None, distance='Euclidean', p=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
