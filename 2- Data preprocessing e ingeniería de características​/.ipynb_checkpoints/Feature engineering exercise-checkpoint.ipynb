{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Data preprocessing e ingeniería de características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingeniería de características. Ejercicio práctico con los datos de Pokémon:\n",
    "\n",
    "- Handling missing data\n",
    "- Grouping sparse classes\n",
    "- Bin numerical data\n",
    "- Handling outliers\n",
    "- Transform variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "# Figures inline and set visualization style\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "pt = np.get_printoptions()['threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar los datos\n",
    "df = pd.read_csv('./data/pokemon.csv')\n",
    "# ver los 10 primeros vectores de características\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver valores únicos que toma la variable 'Type 2'\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuántos valores nulos tiene la variable 'Type 2' en relación al resto de variables?\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotear histograma para ver distribución de la variable 'Type 2'\n",
    "sns..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rellenar valores nulos de la variable 'Type 2' con 'Unknown'\n",
    "df['Type 2']...\n",
    "# comprobar que efectivamente ya no hay nulos en la matriz de datos\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotear histograma para ver nuevamente la distribución de la variable 'Type 2'\n",
    "sns..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping sparse classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear variable 'has_2nd_type' que determine 'Known' o 'Unknown' en función de si 'Type 2' es conocido o no\n",
    "df['has_2nd_type'] = ...\n",
    "\n",
    "# nos quedamos con las variables ['Type 1', 'Type 2', 'has_2nd_type', 'Attack', 'Defense']\n",
    "df_reduced = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotear histograma para ver la distribución de la variable 'has_2nd_type' que acabamos de crear\n",
    "sns..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendríamos que ver cómo los datos estarían ahora muy bien balanceados en función de si 'Type 2' es conocido o no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chequear el boxplot de valores de la variable 'Atack'\n",
    "sns...\n",
    "# calcular los valores umbrales basados en los percentiles\n",
    "upper_limit_attack = ...\n",
    "print(upper_limit_attack)\n",
    "lower_limit_attack = ...\n",
    "print(lower_limit_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# qué Pokémons tendrían unos valores de ataque que se podrían considerar como outliers según los percentiles usados?\n",
    "df_reduced[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacer el mismo ejercicio con la std respecto del valor medio\n",
    "sns..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qué Pokémons tendrían unos valores de ataque que se podrían considerar como outliers según las desviaciones típicas?\n",
    "mean_attack = ...\n",
    "std_attack = ...\n",
    "# mostrar upper y lower limits según las std elegidas\n",
    "print(...)\n",
    "print(...)\n",
    "df_reduced[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elegir uno de los dos métodos para eliminar los outliers > umbral superior\n",
    "df_reduced_normal = ...\n",
    "df_reduced_normal.info()\n",
    "# plotear distribución en base al método empleado\n",
    "sns..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De este modo eliminaremos un porcentaje mínimo de datos (en torno a un 1%-5%) que muestran valores lejos de lo que podríamos considerar como \"normal\" o patrón que queremos modelar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear bins de tamaño 4 para las variables 'Attack' y 'Defense' y asignar los valores a 2 nuevas variables: 'CatAttack' y 'CatDefense'\n",
    "df_reduced_normal['CatAttack'] = ...\n",
    "df_reduced_normal['CatDefense']= ...\n",
    "df_reduced_normal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminar las variables 'Attack' y 'Defense'\n",
    "df_reduced_normal_bins = ...\n",
    "df_reduced_normal_bins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se debería obtener una categorización de ataque y defensa mucho más reducida y manejable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usar label encoder para transformar la variable 'Type 1' a tipo numérico\n",
    "type1_le = LabelEncoder()\n",
    "type1_le_labels = ...\n",
    "df_reduced_normal_bins['Type1_id'] = type1_le_labels\n",
    "# comprobar índices asociados a cada valor categórico de 'Type 1'\n",
    "type1_mappings = ...\n",
    "type1_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrar la variable numérica 'Type 1' y 'Type 2' y ver tabla resultante\n",
    "df_reduced_normal_bins_encoded = ...\n",
    "df_reduced_normal_bins_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usar 'get_dummies' para obtener un valor numérico para la variable categórica 'has_2nd_type'\n",
    "df_reduced_normal_bins_encoded_trans = ...\n",
    "df_reduced_normal_bins_encoded_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotear el patrón (valor medio) correspondiente a cada valor de la variable 'Type 2'\n",
    "plt.figure(figsize=(12,8))\n",
    "for type2 in ...\n",
    "    plt.plot(..., label=type2)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya podemos trabajar los datos con modelos de ML para lanzar predicciones (lo veremos más adelante a lo largo del curso...). Repaso de lo que hemos visto en este notebook:\n",
    "\n",
    "- Hemos seleccionado las columnas que más información aportan\n",
    "- Hemos trabajado la presencia de valores nulos\n",
    "- Hemos eliminado valores atípicos (posibles outliers) que pueden influir en la eficiencia y la bondad del ajuste de los modelos \n",
    "- Hemos transformado variables categóricas o discretas en numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's next?\n",
    "\n",
    "- Métodos y estrategias para el preprocesado de los datos\n",
    "- Generación y aprendizaje de modelos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
