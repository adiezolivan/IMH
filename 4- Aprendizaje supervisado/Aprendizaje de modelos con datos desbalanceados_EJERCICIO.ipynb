{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MÓDULO 4: LA CIENCIA DE DATOS Y LOS MODELOS DE ANALÍTICA PREDICTIVA EN LA INDUSTRIA 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Aprendizaje supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio sobre imbalanced data\n",
    "\n",
    "En la mayoría de los casos resulta muy complejo el hecho de aprender un modelo supervisado robusto y preciso si el dataset está muy desbalanceado; es decir, hay un gran volumen de datos correspondientes a una clase o valor de variable objetivo y unos pocos datos correspondientes a otra clase o valor.\n",
    "\n",
    "En este notebook vamos a trabajar los siguientes conceptos:\n",
    "- Técnicas de resampling: oversampling (RandomOverSampler, SMOTE y ADASYN) y undersampling (RandomUnderSampler, TomekLinks y EditedNearestNeighbours)\n",
    "- Modelos de clasificación supervisada: árboles de decisión, kNN y redes neuronales\n",
    "\n",
    "La idea es aplicar los diferentes modelos al conjunto de datos desbalanceado antes y después de utilizar las técnicas de resampling, comparando los resultados obtenidos. \n",
    "\n",
    "El ejercicio consistirá en aplicar el mismo pipeline definido para el ejemplo con otro conjunto de datos proporcionado y plantear un nuevo modelo clasificatorio.\n",
    "\n",
    "Referencias: https://www.jeremyjordan.me/imbalanced-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar los datos que vamos a trabajar sobre la calidad de un vino portugués. \n",
    "Están disponibles en https://archive.ics.uci.edu/ml/datasets/wine+quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wine quality dataset contains 12 features\n",
    "# Target class derived as target: <=4 (score between 1 and 10)\n",
    "df = pd.read_csv('wine_quality.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos los datos, separando variables predictoras, en X, y variable objetivo a predecir, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.values[:,:-1], df.values[:,-1]\n",
    "print(np.unique(y))\n",
    "# pasamos los valores de y número entero {0,1}\n",
    "y = (y==1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizar el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así comprobamos visualmente la distribución de cada valor de clase y podemos apreciar claramente la naturaleza desbalanceada del dataset. Para ello, aplicamos una técnica de reducción de dimensionalidad, PCA, quedándonos con los 2 primeros componentes principales para una visualización óptima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "# Reduce dataset to 2 feature dimensions in order to visualize the data\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "X_reduced = pca.transform(X)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize= (15,5))\n",
    "\n",
    "ax[0].scatter(X_reduced[y == 0, 0], X_reduced[y == 0, 1], label=\"low quality wine\", alpha=0.2)\n",
    "ax[0].scatter(X_reduced[y == 1, 0], X_reduced[y == 1, 1], label=\"high quality wine\", alpha=0.2)\n",
    "ax[0].set_title('PCA of original dataset')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1] = sns.countplot(y)\n",
    "ax[1].set_title('Number of observations per class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos el dataset en conjuntos de entrenamiento y test para validar el modelo predictor de la calidad del vino que queremos generar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline con diferentes métodos para gestionar datos desbalanceados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos el método 'model_resampling_pipeline(...)' para comparar los diferentes métodos de resampling. En concreto, usaremos los siguientes:\n",
    "- oversampling: RandomOverSampler, SMOTE, ADASYN\n",
    "- undersampling: RandomUnderSampler, TomekLinks, EditedNearestNeighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "from collections import Counter\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks, EditedNearestNeighbours\n",
    "\n",
    "\n",
    "def model_resampling_pipeline(X_train, \n",
    "                              X_test, \n",
    "                              y_train, \n",
    "                              y_test, \n",
    "                              model):\n",
    "    results = {'ordinary': {},\n",
    "               'class_weight': {},\n",
    "               'oversample': {},\n",
    "               'undersample': {}}\n",
    "    \n",
    "    # ------ No balancing ------\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "    precision, recall, fscore, support = metrics.precision_recall_fscore_support(y_test, predictions)\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_test, predictions).ravel()\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    results['ordinary'] = {'accuracy': accuracy, 'precision': precision, 'recall': recall, \n",
    "                          'fscore': fscore, 'n_occurences': support,\n",
    "                          'predictions_count': Counter(predictions),\n",
    "                          'tp': tp, 'tn': tn, 'fp': fp, 'fn': fn,\n",
    "                          'auc': auc}\n",
    "    \n",
    "    \n",
    "    # ------ Class weight ------\n",
    "    if 'class_weight' in model.get_params().keys():\n",
    "        model.set_params(class_weight='balanced')\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "        precision, recall, fscore, support = metrics.precision_recall_fscore_support(y_test, predictions)\n",
    "        tn, fp, fn, tp = metrics.confusion_matrix(y_test, predictions).ravel()\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions, pos_label=1)\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "        results['class_weight'] = {'accuracy': accuracy, 'precision': precision, 'recall': recall, \n",
    "                                  'fscore': fscore, 'n_occurences': support,\n",
    "                                  'predictions_count': Counter(predictions),\n",
    "                                  'tp': tp, 'tn': tn, 'fp': fp, 'fn': fn,\n",
    "                                  'auc': auc}\n",
    "\n",
    "    \n",
    "    # ------------ OVERSAMPLING TECHNIQUES ------------\n",
    "    print('------ Oversampling methods ------')\n",
    "    techniques = [RandomOverSampler(),\n",
    "                  SMOTE(),\n",
    "                  ADASYN()]\n",
    "    \n",
    "    for sampler in techniques:\n",
    "        technique = sampler.__class__.__name__\n",
    "        print(f'Technique: {technique}')\n",
    "        print(f'Before resampling: {sorted(Counter(y_train).items())}')\n",
    "        X_resampled, y_resampled = sampler.fit_sample(X_train, y_train)\n",
    "        print(f'After resampling: {sorted(Counter(y_resampled).items())}')\n",
    "\n",
    "        model.fit(X_resampled, y_resampled)\n",
    "        predictions = model.predict(X_test)\n",
    "        accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "        precision, recall, fscore, support = metrics.precision_recall_fscore_support(y_test, predictions)\n",
    "        tn, fp, fn, tp = metrics.confusion_matrix(y_test, predictions).ravel()\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions, pos_label=1)\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "        results['oversample'][technique] = {'accuracy': accuracy, \n",
    "                                            'precision': precision, \n",
    "                                            'recall': recall,\n",
    "                                            'fscore': fscore, \n",
    "                                            'n_occurences': support,\n",
    "                                            'predictions_count': Counter(predictions),\n",
    "                                            'tp': tp, 'tn': tn, 'fp': fp, 'fn': fn,\n",
    "                                            'auc': auc}\n",
    "\n",
    "    \n",
    "    # ------------ UNDERSAMPLING TECHNIQUES ------------\n",
    "    print('------ Undersampling methods ------')\n",
    "    techniques = [RandomUnderSampler(),                  \n",
    "                  TomekLinks(),\n",
    "                  EditedNearestNeighbours()]\n",
    "    \n",
    "    for sampler in techniques:\n",
    "        technique = sampler.__class__.__name__\n",
    "        print(f'Technique: {technique}')\n",
    "        print(f'Before resampling: {sorted(Counter(y_train).items())}')\n",
    "        X_resampled, y_resampled = sampler.fit_sample(X_train, y_train)\n",
    "        print(f'After resampling: {sorted(Counter(y_resampled).items())}')\n",
    "\n",
    "        model.fit(X_resampled, y_resampled)\n",
    "        predictions = model.predict(X_test)\n",
    "        accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "        precision, recall, fscore, support = metrics.precision_recall_fscore_support(y_test, predictions)\n",
    "        tn, fp, fn, tp = metrics.confusion_matrix(y_test, predictions).ravel()\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions, pos_label=1)\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "        results['undersample'][technique] = {'accuracy': accuracy, \n",
    "                                            'precision': precision, \n",
    "                                            'recall': recall,\n",
    "                                            'fscore': fscore, \n",
    "                                            'n_occurences': support,\n",
    "                                            'predictions_count': Counter(predictions),\n",
    "                                            'tp': tp, 'tn': tn, 'fp': fp, 'fn': fn,\n",
    "                                            'auc': auc}\n",
    "        \n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el objetivo de evaluar visualmente los resultados obtenidos por los modelos que vamos a aplicar, definimos la función 'evaluate_method(...)' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_method(results, \n",
    "                    method, \n",
    "                    metrics = ['precision', 'recall', 'fscore']):\n",
    "    fig, ax = plt.subplots(1, 7, sharey=True, figsize=(16, 6))\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax[i*2].axhline(results['ordinary'][metric][0], label='No Resampling')\n",
    "        ax[i*2+1].axhline(results['ordinary'][metric][1], label='No Resampling')\n",
    "        \n",
    "        if results['class_weight']:\n",
    "            ax[i*2].bar(0, results['class_weight'][metric][0], label='Adjust Class Weight')\n",
    "            ax[i*2+1].bar(0, results['class_weight'][metric][1], label='Adjust Class Weight')\n",
    "            \n",
    "        ax[0].legend(loc='upper center', bbox_to_anchor=(9, 1.01),\n",
    "                     ncol=1, fancybox=True, shadow=True)\n",
    "        \n",
    "        for j, (technique, result) in enumerate(results[method].items()):\n",
    "            ax[i*2].bar(j+1, result[metric][0], label=technique)\n",
    "            \n",
    "            ax[i*2+1].bar(j+1, result[metric][1], label=technique)\n",
    "        \n",
    "        \n",
    "        ax[i*2].set_title(f'Low quality wine: \\n{metric}')\n",
    "        ax[i*2+1].set_title(f'High quality wine: \\n{metric}')\n",
    "    \n",
    "    # AUC vis\n",
    "    ax[6].set_title(f'Area under curve')\n",
    "    ax[6].axhline(results['ordinary']['auc'], label='No Resampling')\n",
    "    if results['class_weight']:\n",
    "        ax[6].bar(0, results['class_weight']['auc'], label='Adjust Class Weight')\n",
    "    for j, (technique, result) in enumerate(results[method].items()):\n",
    "        ax[6].bar(j+1, result['auc'], label=technique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicaremos unos modelos supervisados sencillos, los vistos en clase:\n",
    "- Árboles de decisión: DecisionTreeClassifier\n",
    "- kNN: KNeighborsClassifier\n",
    "- Redes neuronales: MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizar un árbol de decisión entrenado con datos desbalanceados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=4)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "from IPython.display import Image  \n",
    "from sklearn.externals.six import StringIO  \n",
    "import pydot  \n",
    "from sklearn import tree\n",
    "\n",
    "dot_data = StringIO()  \n",
    "tree.export_graphviz(model, out_file=dot_data)\n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph[0].create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "results = model_resampling_pipeline(X_train, X_test, y_train, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_method(results, 'oversample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_method(results, 'undersample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier()\n",
    "results = model_resampling_pipeline(X_train, X_test, y_train, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_method(results, 'oversample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_method(results, 'undersample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=(50, 50), activation='relu', solver='sgd')\n",
    "results = model_resampling_pipeline(X_train, X_test, y_train, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_method(results, 'oversample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_method(results, 'undersample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hacer lo mismo utilizando otro dataset y comentar resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar los datos que vamos a trabajar sobre el índice de crimen en US. \n",
    "Están disponibles en http://archive.ics.uci.edu/ml/datasets/communities+and+crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# US crime dataset contains 100 features, descriptions found here: \n",
    "# Target class derived as target: >0.65\n",
    "df = pd.read_csv('communities.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proponer otro método de aprendizaje supervisado y ver si mejora los resultados obtenidos por los 3 propuestos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
